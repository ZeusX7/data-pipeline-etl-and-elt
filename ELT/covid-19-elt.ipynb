{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19d50a76",
   "metadata": {},
   "source": [
    "## Extração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f856ffd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import de libs necessárias para o processo de data cleaning\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import urllib.request\n",
    "import json\n",
    "import zipfile\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Bibliotecas de banco devem vir por último\n",
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "383bd4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# armazenando os ids de cada arquivo que serão baixados posteriormente\n",
    "files_ids = [\"99b42b09-95af-47de-8411-ab99c380c3ef\",\n",
    "             \"9664de94-9f07-4adc-848d-b6ef56510762\",\n",
    "             \"bceb5759-5500-49db-bc86-b038892acc06\",\n",
    "             \"ca7fb968-3a2c-44ff-a2e8-730d1a689407\",\n",
    "              \"c675899c-69d9-4dc8-bb11-00afc9636a3b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2751abc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baixando arquivo JSON...\n",
      "Arquivo salvo em: datasets\\99b42b09-95af-47de-8411-ab99c380c3ef.json\n",
      "Baixando arquivo JSON...\n",
      "Erro ao baixar o arquivo: HTTP Error 404: Not Found\n",
      "Baixando arquivo JSON...\n",
      "Arquivo salvo em: datasets\\bceb5759-5500-49db-bc86-b038892acc06.json\n",
      "Baixando arquivo JSON...\n",
      "Arquivo salvo em: datasets\\ca7fb968-3a2c-44ff-a2e8-730d1a689407.json\n",
      "Baixando arquivo JSON...\n",
      "Arquivo salvo em: datasets\\c675899c-69d9-4dc8-bb11-00afc9636a3b.json\n",
      "Todos os downloads foram concluídos com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Diretório onde o dataset será salvo\n",
    "dataset_dir = \"datasets\"\n",
    "os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    # URL direta do arquivo JSON\n",
    "    for fileId in files_ids:\n",
    "        url = f'http://dados.recife.pe.gov.br/datastore/dump/{fileId}?format=json'\n",
    "        # Nome do arquivo de saída\n",
    "        output_path = os.path.join(dataset_dir, f\"{fileId}.json\")\n",
    "        try:\n",
    "            print(\"Baixando arquivo JSON...\")\n",
    "            urllib.request.urlretrieve(url, output_path)\n",
    "            print(f\"Arquivo salvo em: {output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao baixar o arquivo: {e}\")\n",
    "    print(\"Todos os downloads foram concluídos com sucesso!\")\n",
    "except Exception as e:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564828b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe inicializado com sucesso!\n",
      "4 jsons adicionados ao df\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = None\n",
    "successful_files = 0\n",
    "\n",
    "for fileName in files_ids:\n",
    "    json_dir = f\"datasets/{fileName}.json\"\n",
    "    # Abre e carrega o conteúdo do arquivo JSON em um dicionário Python\n",
    "    if os.path.exists(json_dir):\n",
    "        \n",
    "        successful_files += 1\n",
    "\n",
    "        with open(json_dir, 'r', encoding='utf-8') as f:\n",
    "            json_data = json.load(f)\n",
    "            \n",
    "        # Extrai os nomes das colunas da lista \"fields\" e as tuplas da lista \"records\"\n",
    "        tuples = json_data['records']\n",
    "        cols = [field['id'] for field in json_data['fields']]\n",
    "        \n",
    "        # se for o primeiro json lido, vamos instanciar nosso dataFrame pandas que será usado no resto da aplicação\n",
    "        if(fileName == files_ids[0]):\n",
    "            df = pd.DataFrame(data=tuples, columns=cols)\n",
    "        else:\n",
    "            # caso contrário, vamos criar um dataframe temporário e concatenar com o já existente\n",
    "            temp_df =  pd.DataFrame(data=tuples, columns=cols)\n",
    "            df = pd.concat([df, temp_df], ignore_index=True)\n",
    "        \n",
    "print(\"Dataframe inicializado com sucesso!\")\n",
    "print(f\"{successful_files} jsons adicionados ao df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "217f0d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73996 linhas e 14 colunas\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['_id', 'faixa_etaria', 'idade', 'sexo', 'raca_cor', 'municipio',\n",
       "       'grupo', 'categoria', 'lote', 'vacina_fabricante', 'descricao_dose',\n",
       "       'cnes', 'sistema_origem', 'data_vacinacao'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos dar uma olhadinha no dataframe pra ver se tá tudo certo\n",
    "print(f\"{df.shape[0]} linhas e {df.shape[1]} colunas\")\n",
    "df.head()\n",
    "#Verificando as colunas do dataframe\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9df3f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banco 'covid_elt' criado com sucesso!\n",
      "Inseridos registros de 0 a 999\n",
      "Inseridos registros de 1000 a 1999\n",
      "Inseridos registros de 2000 a 2999\n",
      "Inseridos registros de 3000 a 3999\n",
      "Inseridos registros de 4000 a 4999\n",
      "Inseridos registros de 5000 a 5999\n",
      "Inseridos registros de 6000 a 6999\n",
      "Inseridos registros de 7000 a 7999\n",
      "Inseridos registros de 8000 a 8999\n",
      "Inseridos registros de 9000 a 9999\n",
      "Inseridos registros de 10000 a 10999\n",
      "Inseridos registros de 11000 a 11999\n",
      "Inseridos registros de 12000 a 12999\n",
      "Inseridos registros de 13000 a 13999\n",
      "Inseridos registros de 14000 a 14999\n",
      "Inseridos registros de 15000 a 15999\n",
      "Inseridos registros de 16000 a 16999\n",
      "Inseridos registros de 17000 a 17999\n",
      "Inseridos registros de 18000 a 18999\n",
      "Inseridos registros de 19000 a 19999\n",
      "Inseridos registros de 20000 a 20999\n",
      "Inseridos registros de 21000 a 21999\n",
      "Inseridos registros de 22000 a 22999\n",
      "Inseridos registros de 23000 a 23999\n",
      "Inseridos registros de 24000 a 24999\n",
      "Inseridos registros de 25000 a 25999\n",
      "Inseridos registros de 26000 a 26999\n",
      "Inseridos registros de 27000 a 27999\n",
      "Inseridos registros de 28000 a 28999\n",
      "Inseridos registros de 29000 a 29999\n",
      "Inseridos registros de 30000 a 30999\n",
      "Inseridos registros de 31000 a 31999\n",
      "Inseridos registros de 32000 a 32999\n",
      "Inseridos registros de 33000 a 33999\n",
      "Inseridos registros de 34000 a 34999\n",
      "Inseridos registros de 35000 a 35999\n",
      "Inseridos registros de 36000 a 36999\n",
      "Inseridos registros de 37000 a 37999\n",
      "Inseridos registros de 38000 a 38999\n",
      "Inseridos registros de 39000 a 39999\n",
      "Inseridos registros de 40000 a 40999\n",
      "Inseridos registros de 41000 a 41999\n",
      "Inseridos registros de 42000 a 42999\n",
      "Inseridos registros de 43000 a 43999\n",
      "Inseridos registros de 44000 a 44999\n",
      "Inseridos registros de 45000 a 45999\n",
      "Inseridos registros de 46000 a 46999\n",
      "Inseridos registros de 47000 a 47999\n",
      "Inseridos registros de 48000 a 48999\n",
      "Inseridos registros de 49000 a 49999\n",
      "Inseridos registros de 50000 a 50999\n",
      "Inseridos registros de 51000 a 51999\n",
      "Inseridos registros de 52000 a 52999\n",
      "Inseridos registros de 53000 a 53999\n",
      "Inseridos registros de 54000 a 54999\n",
      "Inseridos registros de 55000 a 55999\n",
      "Inseridos registros de 56000 a 56999\n",
      "Inseridos registros de 57000 a 57999\n",
      "Inseridos registros de 58000 a 58999\n",
      "Inseridos registros de 59000 a 59999\n",
      "Inseridos registros de 60000 a 60999\n",
      "Inseridos registros de 61000 a 61999\n",
      "Inseridos registros de 62000 a 62999\n",
      "Inseridos registros de 63000 a 63999\n",
      "Inseridos registros de 64000 a 64999\n",
      "Inseridos registros de 65000 a 65999\n",
      "Inseridos registros de 66000 a 66999\n",
      "Inseridos registros de 67000 a 67999\n",
      "Inseridos registros de 68000 a 68999\n",
      "Inseridos registros de 69000 a 69999\n",
      "Inseridos registros de 70000 a 70999\n",
      "Inseridos registros de 71000 a 71999\n",
      "Inseridos registros de 72000 a 72999\n",
      "Inseridos registros de 73000 a 73995\n",
      "('1', '50 a 54 anos', '53', 'MASCULINO', 'PRETA', 'RECIFE', 'TRABALHADORES DA SAÚDE', '', 'FM3457', '3 - COMIRNATY (PFIZER)', '3', 'DS 1: CNES: 000507 - POLICLÍNICA GOUVEIA DE BARROS', 'Conecta Recife', '2021-12-06T00:00:00')\n",
      "Tabela 'stg_casos_covid' carregada com sucesso.\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "\n",
    "# carregar o arquivo JSON com as configurações de conexão\n",
    "with open('../config.json', 'r') as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "\n",
    "# 0. Criar banco covid_elt se não existir\n",
    "try:\n",
    "    conn_postgres = psycopg2.connect(\n",
    "        dbname=\"postgres\",\n",
    "        user=config[\"user\"],\n",
    "        password=config[\"password\"],\n",
    "        host=config[\"host\"],\n",
    "        port=config[\"port\"]\n",
    "    )\n",
    "    conn_postgres.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "    cur = conn_postgres.cursor()\n",
    "    cur.execute(\"SELECT 1 FROM pg_database WHERE datname='covid_elt';\")\n",
    "    exists = cur.fetchone()\n",
    "    if not exists:\n",
    "        cur.execute(\"CREATE DATABASE covid_elt;\")\n",
    "        print(\"Banco 'covid_elt' criado com sucesso!\")\n",
    "    else:\n",
    "        print(\"Banco 'covid_elt' já existe.\")\n",
    "    cur.close()\n",
    "    conn_postgres.close()\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao criar banco: {e}\")\n",
    "\n",
    "# 1. Conexão manual com client_encoding forçado ao banco covid_elt\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"covid_elt\",\n",
    "    user=config[\"user\"],\n",
    "    password=config[\"password\"],\n",
    "    host=config[\"host\"],\n",
    "    port=config[\"port\"]\n",
    ")\n",
    "conn.set_client_encoding('UTF8')  # forçando o encoding correto\n",
    "\n",
    "# 2. Conectando com SQLAlchemy usando esse conn\n",
    "engine = create_engine(\"postgresql+psycopg2://\", creator=lambda: conn)\n",
    "\n",
    "nome_tabela = \"stg_casos_covid\"\n",
    "\n",
    "# 3. Preparação dos dados (só pra garantir segurança total)\n",
    "df.fillna('', inplace=True)\n",
    "df = df.astype(str)\n",
    "\n",
    "# 4. Inserção em chunks\n",
    "chunk_size = 1000\n",
    "for start in range(0, len(df), chunk_size):\n",
    "    end = min(start + chunk_size, len(df))\n",
    "    df_chunk = df.iloc[start:end]\n",
    "    try:\n",
    "        df_chunk.to_sql(nome_tabela, con=engine, if_exists='append' if start > 0 else 'replace', index=False)\n",
    "        print(f\"Inseridos registros de {start} a {end - 1}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao inserir registros de {start} a {end - 1}: {e}\")\n",
    "        break\n",
    "\n",
    "# 5. Verificação\n",
    "try:\n",
    "    with engine.connect() as conn_check:\n",
    "        result = conn_check.execute(text(f\"SELECT * FROM {nome_tabela} LIMIT 1\"))\n",
    "        for row in result:\n",
    "            print(row)\n",
    "    print(f\"Tabela '{nome_tabela}' carregada com sucesso.\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao consultar a tabela: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1e1bd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
